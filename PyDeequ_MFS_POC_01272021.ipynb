{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data quality at scale with PyDeequ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains examples of the below 5 main functions of Deequ\n",
    "1. Metrics Computation\n",
    "2. Constraint verification\n",
    "3. Data Profiling\n",
    "4. Automatic constraint suggestion\n",
    "5. Metrics Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img\\Pydeequ_components.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "import pydeequ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.jars.packages\", pydeequ.deequ_maven_coord)\n",
    "    .config(\"spark.jars.excludes\", pydeequ.f2j_maven_coord)\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('ACCOUNT_MANAGEMENT_FACT_20210122.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+------------------+\n",
      "|     entity|            instance|                name|             value|\n",
      "+-----------+--------------------+--------------------+------------------+\n",
      "|     Column|         ACCOUNT_NBR|        Completeness|               1.0|\n",
      "|     Column|         ACCOUNT_NBR|       CountDistinct|           31177.0|\n",
      "|     Column|    PRIN_BALANCE_AMT|             Maximum|         157631.54|\n",
      "|     Column|    PRIN_BALANCE_AMT|Mean (where: PRIN...|25701.115574193544|\n",
      "|    Dataset|                   *|                Size|           31177.0|\n",
      "|Mutlicolumn|FINANCED_AMT,PRIN...|         Correlation|0.8645646819614178|\n",
      "|     Column|   CURRENT_LOAN_TERM|          Compliance|0.9998717002918819|\n",
      "|Mutlicolumn|FINANCED_AMT,ORIG...|         Correlation|               1.0|\n",
      "+-----------+--------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import *\n",
    "\n",
    "analysisResult = AnalysisRunner(spark) \\\n",
    "                    .onData(df) \\\n",
    "                    .addAnalyzer(Size()) \\\n",
    "                    .addAnalyzer(Completeness(\"ACCOUNT_NBR\")) \\\n",
    "                    .addAnalyzer(Maximum(\"PRIN_BALANCE_AMT\")) \\\n",
    "                    .addAnalyzer(CountDistinct(\"ACCOUNT_NBR\")) \\\n",
    "                    .addAnalyzer(Mean(\"PRIN_BALANCE_AMT\",\"PRIN_BALANCE_AMT <> 0\")) \\\n",
    "                    .addAnalyzer(Compliance(\"CURRENT_LOAN_TERM\", \"CURRENT_LOAN_TERM between 24 and 100\")) \\\n",
    "                    .addAnalyzer(Correlation(\"FINANCED_AMT\", \"ORIG_NOTE_AMT\")) \\\n",
    "                    .addAnalyzer(Correlation(\"FINANCED_AMT\", \"PRIN_BALANCE_AMT\")) \\\n",
    "                    .run()\n",
    "                    \n",
    "analysisResult_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult)\n",
    "analysisResult_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of computable metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img\\Metrics.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraint Verification ( Data Quality tests)\n",
    "\n",
    "After analyzing and understanding the data, we want to verify that the properties we have derived also hold for new versions of the dataset. By defining assertions on the data distribution as part of a data pipeline, we can ensure that every processed dataset is of high quality, and that any application consuming the data can rely on it.\n",
    "\n",
    "In the below example , We are running the below tests on the 'ACCOUNT MANAGEMENT FACT' dataset from MFS EDW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img\\DQ_Validations_Sample.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Callback server started!\n",
      "+--------------------+-----------+------------+--------------------+-----------------+--------------------+\n",
      "|               check|check_level|check_status|          constraint|constraint_status|  constraint_message|\n",
      "+--------------------+-----------+------------+--------------------+-----------------+--------------------+\n",
      "|Account Managemen...|    Warning|     Warning|CompletenessConst...|          Success|                    |\n",
      "|Account Managemen...|    Warning|     Warning|UniquenessConstra...|          Success|                    |\n",
      "|Account Managemen...|    Warning|     Warning|MaxLengthConstrai...|          Success|                    |\n",
      "|Account Managemen...|    Warning|     Warning|ComplianceConstra...|          Success|                    |\n",
      "|Account Managemen...|    Warning|     Warning|ComplianceConstra...|          Failure|Value: 0.99839625...|\n",
      "|Account Managemen...|    Warning|     Warning|ComplianceConstra...|          Success|                    |\n",
      "+--------------------+-----------+------------+--------------------+-----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.checks import *\n",
    "from pydeequ.verification import *\n",
    "\n",
    "check = Check(spark, CheckLevel.Warning, \"Account Management Fact Data Quality Checks\")\n",
    "\n",
    "checkResult = VerificationSuite(spark) \\\n",
    "    .onData(df) \\\n",
    "    .addCheck(\n",
    "        check.isComplete(\"LOAN_PRODUCT_CODE\")  \\\n",
    "        .isUnique(\"ACCOUNT_NBR\")  \\\n",
    "        .hasMaxLength(\"VIN\", lambda x: x == 17,\"WHERE VIN <> -1\") \\\n",
    "        .isContainedIn(\"LOAN_PRODUCT_CODE\", [\"RTL\", \"LSE\"]) \\\n",
    "        .satisfies(\"OTH_CHRG_PD_AMT_MTD < ORIG_NOTE_AMT\",\"Business Logic validation\",lambda x: x == 1.0)\\\n",
    "         .isNonNegative(\"ORIG_NOTE_AMT\")) \\\n",
    "    .run()\n",
    "    \n",
    "checkResult_df = VerificationResult.checkResultsAsDataFrame(spark, checkResult)\n",
    "checkResult_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints available for user-defined data quality checks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img\\Constraints.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydeequ.profiles import *\n",
    "\n",
    "result = ColumnProfilerRunner(spark) \\\n",
    "            .onData(df) \\\n",
    "            .run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer https://github.com/awslabs/python-deequ/blob/master/pydeequ/profiles.py for the whole list of metrics that can be profiled for standard columns and numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'PAYMENT_PATTERN'\n",
      "\t completeness: 0.9999358501459409\n",
      "\t approximate number of distinct values: 126\n",
      "\t datatype: String\n",
      "Column 'VEHICLE_MSRP'\n",
      "\t completeness: 1.0\n",
      "\t approximate number of distinct values: 4604\n",
      "\t datatype: Fractional\n",
      "Column 'DEALER_DIM_ID'\n",
      "\t completeness: 1.0\n",
      "\t approximate number of distinct values: 597\n",
      "\t datatype: Integral\n",
      "Column 'PRIN_BALANCE_AMT'\n",
      "\t completeness: 1.0\n",
      "\t approximate number of distinct values: 28777\n",
      "\t datatype: Fractional\n"
     ]
    }
   ],
   "source": [
    "# Printing profile information for few columns as example\n",
    "for col, profile in result.profiles.items():\n",
    "    if col in (\"PAYMENT_PATTERN\",\"PRIN_BALANCE_AMT\",\"VEHICLE_MSRP\",\"DEALER_DIM_ID\"):\n",
    "        print(f'Column \\'{col}\\'')\n",
    "        print('\\t',f'completeness: {profile.completeness}')\n",
    "        print('\\t',f'approximate number of distinct values: {profile.approximateNumDistinctValues}')\n",
    "        print('\\t',f'datatype: {profile.dataType}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended profile for Numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics of 'Principal Balance Amount':\n",
      "\t minimum: 0.0\n",
      "\t maximum: 157631.54\n",
      "\t mean: 24916.32351509125\n",
      "\t standard deviation: 8817.203152256005\n"
     ]
    }
   ],
   "source": [
    "PrinBalanceAmountProfile = result.profiles['PRIN_BALANCE_AMT']\n",
    "\n",
    "print(f'Statistics of \\'Principal Balance Amount\\':')\n",
    "print('\\t',f\"minimum: {PrinBalanceAmountProfile.minimum}\")\n",
    "print('\\t',f\"maximum: {PrinBalanceAmountProfile.maximum}\")\n",
    "print('\\t',f\"mean: {PrinBalanceAmountProfile.mean}\")\n",
    "print('\\t',f\"standard deviation: {PrinBalanceAmountProfile.stdDev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Constraint Suggestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deequ can automatically suggest useful constraints based on the data distribution. Deequ first runs a data profiling method and then applies a set of rules on the result. Refer the link https://github.tfs.toyota.com/radhakk/Deequ-POC/blob/master/Deequ%20-%20Automatic%20Constraint%20Suggestion.ipynb to view the example for Automatic Constraint generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Repository - Storing Computed Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics Repository allows us to store the metrics in json format on the local disk (note that it also supports HDFS and S3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics_file path: C:\\Users\\radhakk\\AppData\\Local\\Temp\\1611594580030-0\\metrics.json\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.repository import *\n",
    "\n",
    "metrics_file = FileSystemMetricsRepository.helper_metrics_file(spark, 'metrics.json')\n",
    "print(f'metrics_file path: {metrics_file}')\n",
    "repository = FileSystemMetricsRepository(spark, metrics_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Each set of metrics that we computed needs be indexed by a so-called ResultKey, which contains a timestamp and supports arbitrary tags in the form of key-value pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_tags = {'tag': 'Analysis1'}\n",
    "resultKey = ResultKey(spark, ResultKey.current_milli_time(), key_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------+------------------+\n",
      "|     entity|            instance|         name|             value|\n",
      "+-----------+--------------------+-------------+------------------+\n",
      "|     Column|         ACCOUNT_NBR| Completeness|               1.0|\n",
      "|     Column|         ACCOUNT_NBR|CountDistinct|           31177.0|\n",
      "|     Column|    PRIN_BALANCE_AMT|      Maximum|         157631.54|\n",
      "|     Column|    PRIN_BALANCE_AMT|         Mean| 24916.32351509125|\n",
      "|    Dataset|                   *|         Size|           31177.0|\n",
      "|Mutlicolumn|FINANCED_AMT,PRIN...|  Correlation|0.8645646819614178|\n",
      "|     Column|   CURRENT_LOAN_TERM|   Compliance|0.9998717002918819|\n",
      "|Mutlicolumn|FINANCED_AMT,ORIG...|  Correlation|               1.0|\n",
      "+-----------+--------------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydeequ.analyzers import *\n",
    "\n",
    "analysisResult1 = AnalysisRunner(spark) \\\n",
    "                    .onData(df) \\\n",
    "                    .addAnalyzer(Size()) \\\n",
    "                    .addAnalyzer(Completeness(\"ACCOUNT_NBR\")) \\\n",
    "                    .addAnalyzer(Maximum(\"PRIN_BALANCE_AMT\")) \\\n",
    "                    .addAnalyzer(CountDistinct(\"ACCOUNT_NBR\")) \\\n",
    "                    .addAnalyzer(Mean(\"PRIN_BALANCE_AMT\")) \\\n",
    "                    .addAnalyzer(Compliance(\"CURRENT_LOAN_TERM\", \"CURRENT_LOAN_TERM between 24 and 100\")) \\\n",
    "                    .addAnalyzer(Correlation(\"FINANCED_AMT\", \"ORIG_NOTE_AMT\")) \\\n",
    "                    .addAnalyzer(Correlation(\"FINANCED_AMT\", \"PRIN_BALANCE_AMT\")) \\\n",
    "                    .useRepository(repository) \\\n",
    "                    .saveOrAppendResult(resultKey) \\\n",
    "                    .run()\n",
    "                    \n",
    "analysisResult_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult)\n",
    "analysisResult_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load back the analysis results into Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------+------------------+-------------+---------+\n",
      "|     entity|            instance|         name|             value| dataset_date|      tag|\n",
      "+-----------+--------------------+-------------+------------------+-------------+---------+\n",
      "|     Column|         ACCOUNT_NBR| Completeness|               1.0|1611594746425|Analysis1|\n",
      "|     Column|         ACCOUNT_NBR|CountDistinct|           31177.0|1611594746425|Analysis1|\n",
      "|     Column|    PRIN_BALANCE_AMT|      Maximum|         157631.54|1611594746425|Analysis1|\n",
      "|     Column|    PRIN_BALANCE_AMT|         Mean| 24916.32351509125|1611594746425|Analysis1|\n",
      "|    Dataset|                   *|         Size|           31177.0|1611594746425|Analysis1|\n",
      "|Mutlicolumn|FINANCED_AMT,PRIN...|  Correlation|0.8645646819614178|1611594746425|Analysis1|\n",
      "|     Column|   CURRENT_LOAN_TERM|   Compliance|0.9998717002918819|1611594746425|Analysis1|\n",
      "|Mutlicolumn|FINANCED_AMT,ORIG...|  Correlation|               1.0|1611594746425|Analysis1|\n",
      "+-----------+--------------------+-------------+------------------+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysisResult_metRep = repository.load() \\\n",
    "                            .before(ResultKey.current_milli_time()) \\\n",
    "                            .getSuccessMetricsAsDataFrame()\n",
    "\n",
    "analysisResult_metRep.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run another Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_tags_2 = {'tag': 'Analysis2'}\n",
    "resultKey_2 = ResultKey(spark, ResultKey.current_milli_time(), key_tags_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------+------------------+\n",
      "|     entity|            instance|         name|             value|\n",
      "+-----------+--------------------+-------------+------------------+\n",
      "|     Column|        FINANCED_AMT|      Maximum|         167721.63|\n",
      "|     Column|        FINANCED_AMT|         Mean|27318.502986175696|\n",
      "|Mutlicolumn|ORIG_NOTE_AMT,PRI...|  Correlation|0.8645646819614178|\n",
      "|     Column|   CURRENT_LOAN_TERM|   Compliance|0.9999358501459409|\n",
      "|     Column|     SRVC_ACCOUNT_ID|CountDistinct|           31177.0|\n",
      "|    Dataset|                   *|         Size|           31177.0|\n",
      "|     Column|     SRVC_ACCOUNT_ID| Completeness|               1.0|\n",
      "|Mutlicolumn|FINANCED_AMT,ORIG...|  Correlation|               1.0|\n",
      "+-----------+--------------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysisResult2 = AnalysisRunner(spark) \\\n",
    "                    .onData(df) \\\n",
    "                    .addAnalyzer(Size()) \\\n",
    "                    .addAnalyzer(Completeness(\"SRVC_ACCOUNT_ID\")) \\\n",
    "                    .addAnalyzer(Maximum(\"FINANCED_AMT\")) \\\n",
    "                    .addAnalyzer(CountDistinct(\"SRVC_ACCOUNT_ID\")) \\\n",
    "                    .addAnalyzer(Mean(\"FINANCED_AMT\")) \\\n",
    "                    .addAnalyzer(Compliance(\"CURRENT_LOAN_TERM\", \"CURRENT_LOAN_TERM between 10 and 100\")) \\\n",
    "                    .addAnalyzer(Correlation(\"FINANCED_AMT\", \"ORIG_NOTE_AMT\")) \\\n",
    "                    .addAnalyzer(Correlation(\"ORIG_NOTE_AMT\", \"PRIN_BALANCE_AMT\")) \\\n",
    "                    .useRepository(repository) \\\n",
    "                    .saveOrAppendResult(resultKey_2) \\\n",
    "                    .run()\n",
    "                    \n",
    "analysisResult2_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult2)\n",
    "analysisResult2_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------------------+-------------+------------------+-------------+---------+\n",
      "|entity     |instance                      |name         |value             |dataset_date |tag      |\n",
      "+-----------+------------------------------+-------------+------------------+-------------+---------+\n",
      "|Column     |FINANCED_AMT                  |Maximum      |167721.63         |1611594746425|Analysis1|\n",
      "|Column     |FINANCED_AMT                  |Mean         |27318.502986175696|1611594746425|Analysis1|\n",
      "|Column     |ACCOUNT_NBR                   |Completeness |1.0               |1611594746425|Analysis1|\n",
      "|Mutlicolumn|ORIG_NOTE_AMT,PRIN_BALANCE_AMT|Correlation  |0.8645646819614178|1611594746425|Analysis1|\n",
      "|Column     |CURRENT_LOAN_TERM             |Compliance   |0.9999358501459409|1611594746425|Analysis1|\n",
      "|Column     |ACCOUNT_NBR                   |CountDistinct|31177.0           |1611594746425|Analysis1|\n",
      "|Column     |SRVC_ACCOUNT_ID               |CountDistinct|31177.0           |1611594746425|Analysis1|\n",
      "|Column     |PRIN_BALANCE_AMT              |Maximum      |157631.54         |1611594746425|Analysis1|\n",
      "|Column     |PRIN_BALANCE_AMT              |Mean         |24916.32351509125 |1611594746425|Analysis1|\n",
      "|Dataset    |*                             |Size         |31177.0           |1611594746425|Analysis1|\n",
      "|Mutlicolumn|FINANCED_AMT,PRIN_BALANCE_AMT |Correlation  |0.8645646819614178|1611594746425|Analysis1|\n",
      "|Column     |CURRENT_LOAN_TERM             |Compliance   |0.9998717002918819|1611594746425|Analysis1|\n",
      "|Column     |SRVC_ACCOUNT_ID               |Completeness |1.0               |1611594746425|Analysis1|\n",
      "|Mutlicolumn|FINANCED_AMT,ORIG_NOTE_AMT    |Correlation  |1.0               |1611594746425|Analysis1|\n",
      "|Column     |FINANCED_AMT                  |Maximum      |167721.63         |1611594953237|Analysis2|\n",
      "|Column     |FINANCED_AMT                  |Mean         |27318.502986175696|1611594953237|Analysis2|\n",
      "|Mutlicolumn|ORIG_NOTE_AMT,PRIN_BALANCE_AMT|Correlation  |0.8645646819614178|1611594953237|Analysis2|\n",
      "|Column     |CURRENT_LOAN_TERM             |Compliance   |0.9999358501459409|1611594953237|Analysis2|\n",
      "|Column     |SRVC_ACCOUNT_ID               |CountDistinct|31177.0           |1611594953237|Analysis2|\n",
      "|Dataset    |*                             |Size         |31177.0           |1611594953237|Analysis2|\n",
      "|Column     |SRVC_ACCOUNT_ID               |Completeness |1.0               |1611594953237|Analysis2|\n",
      "|Mutlicolumn|FINANCED_AMT,ORIG_NOTE_AMT    |Correlation  |1.0               |1611594953237|Analysis2|\n",
      "+-----------+------------------------------+-------------+------------------+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysisResult_metRep_2 = repository.load() \\\n",
    "                            .before(ResultKey.current_milli_time()) \\\n",
    "                            .getSuccessMetricsAsDataFrame()\n",
    "\n",
    "analysisResult_metRep_2.show(analysisResult_metRep_2.count(), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the differences in the dataset_date and tag column and filter our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------------------+-------------+------------------+-------------+---------+\n",
      "|entity     |instance                      |name         |value             |dataset_date |tag      |\n",
      "+-----------+------------------------------+-------------+------------------+-------------+---------+\n",
      "|Column     |FINANCED_AMT                  |Maximum      |167721.63         |1611594953237|Analysis2|\n",
      "|Column     |FINANCED_AMT                  |Mean         |27318.502986175696|1611594953237|Analysis2|\n",
      "|Mutlicolumn|ORIG_NOTE_AMT,PRIN_BALANCE_AMT|Correlation  |0.8645646819614178|1611594953237|Analysis2|\n",
      "|Column     |CURRENT_LOAN_TERM             |Compliance   |0.9999358501459409|1611594953237|Analysis2|\n",
      "|Column     |SRVC_ACCOUNT_ID               |CountDistinct|31177.0           |1611594953237|Analysis2|\n",
      "|Dataset    |*                             |Size         |31177.0           |1611594953237|Analysis2|\n",
      "|Column     |SRVC_ACCOUNT_ID               |Completeness |1.0               |1611594953237|Analysis2|\n",
      "|Mutlicolumn|FINANCED_AMT,ORIG_NOTE_AMT    |Correlation  |1.0               |1611594953237|Analysis2|\n",
      "+-----------+------------------------------+-------------+------------------+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_tags = repository.load() \\\n",
    "        .withTagValues(key_tags_2) \\\n",
    "        .getSuccessMetricsAsDataFrame()\n",
    "\n",
    "filtered_tags.show(filtered_tags.count(), False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations\n",
    "\n",
    "1. Deequ library won't support Spark 3.0 and above as of now . Please refer https://github.com/awslabs/deequ/issues/283\n",
    "2. There is no option in deequ library to write back the anomaly records into file / database. Need to customize to make this happen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Analyse if there is any workaround to make Deequ compatible with Spark 3.0\n",
    "2. Analyse further regarding how the metrics and exception records can be stored in database\n",
    "3. Check the options to create dashboards based on DQ results stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
